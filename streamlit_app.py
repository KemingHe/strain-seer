# Standard library imports
import io
import json
import os
from pathlib import Path
from typing import Dict, List, TypedDict, Optional
import uuid

# Third-party library imports
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image
from scipy import stats
import streamlit as st
from streamlit_image_annotation import pointdet

# Local application imports
from strain_analysis import normalize_points_by_scale, calculate_strain_tensor

# Set page config with favicon
st.set_page_config(
    page_title="Strain Seer - 2D Strain Analysis Tool",
    page_icon="üìç",
    layout="wide"
)

# Type definitions
class Point(TypedDict):
    point: List[float]
    label: str
    label_id: int

class FileData(TypedDict):
    id: str
    filename: str
    order: int
    points: List[Point]
    status: tuple[bool, str]
    deformation_distance: Optional[float]

class AnalysisResults(TypedDict):
    strain_data: List[Dict]
    scale_length: float
    regression_results: Dict[str, Dict]

# Initialize session state
if 'files_data' not in st.session_state:
    st.session_state.files_data = {}
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'last_scale_length' not in st.session_state:
    st.session_state.last_scale_length = 10.0

# Title and description
st.title("Strain Seer - 2D Strain Analysis Tool")
st.markdown("""
## üìä What is 2D Strain Analysis?

2D strain analysis measures material deformation using 5 fiducial markers and 2 scale markers to calculate:
- Œµxx: Stretching/compression in x-direction
- Œµyy: Stretching/compression in y-direction
- Œµxy: Shearing deformation

### üîÑ How It Works

1. Mark 5 fiducial points (red) and 2 scale points (green)
2. Enter scale length to convert pixels to real-world units
3. Input deformation distance for each image
4. View strain analysis and regression results

### üìç Point Labeling Convention

```text
0 ------- 1
|  \   /  |
|    4    |
|  /   \  |
3 ------- 2
```

- Points 0-3: Corner points (clockwise from top-left)
- Point 4: Center point
- Scale points: Calibration markers (green)

### üìè Why We Need Scale Points

```text
Image 1 (1000px)     Image 2 (2000px)
+----------------+   +------------------------+
|                |   |                        |
|  [10mm]        |   |    [10mm]              |
|  |----|        |   |    |----|              |
|                |   |                        |
+----------------+   +------------------------+

Without Scale:           With Scale:
- 100px = ?mm          - 100px = 1mm
- 200px = ?mm          - 200px = 1mm
```

Scale points ensure:
- Consistent measurements across images
- Accurate pixel-to-real-world conversion
- Reproducible results

### üöÄ Step-by-Step Guide

1. **Upload Images**
   - Supported: PNG, JPG, JPEG, GIF, BMP
   - ‚ö†Ô∏è **Important**: Upload files in order
   - Order determines sequence in analysis and plots

2. **Annotate Points**
   - 5 red fiducial points
   - 2 green scale points
   - Enter deformation distance

3. **Run Analysis**
   - Set scale length
   - View results
   - Export data

### üí° Tips for Best Results

- Clear fiducial markers
- Known scale distance
- Well-lit, focused images
- Correct point order (0-4)
- Upload images in sequence
""")

# Define label list with colors
label_list = ['Fiducial', 'Scale']

def validate_annotation(points: List[Point], deformation_distance: Optional[float]) -> tuple[bool, str]:
    """Validate if annotation meets requirements."""
    if not points:
        return False, "Missing"
    
    fiducial_count = sum(1 for p in points if p['label'] == 'Fiducial')
    scale_count = sum(1 for p in points if p['label'] == 'Scale')
    
    if fiducial_count != 5 or scale_count != 2:
        return False, "Incomplete"
    if deformation_distance is None:
        return False, "Missing Distance"
    return True, "Complete"

def save_annotation(file_id: str, filename: str, order: int, points: Optional[List[Point]] = None, deformation_distance: Optional[float] = None) -> None:
    """Save annotation data to session state."""
    current_data = st.session_state.files_data.get(file_id, {
        'id': file_id,
        'filename': filename,
        'order': order,
        'points': [],
        'deformation_distance': None,
        'status': (False, "Missing")
    })
    
    st.session_state.files_data[file_id] = {
        'id': file_id,
        'filename': filename,
        'order': order,
        'points': points or current_data['points'],
        'deformation_distance': deformation_distance if deformation_distance is not None else current_data['deformation_distance'],
        'status': validate_annotation(points or current_data['points'], deformation_distance if deformation_distance is not None else current_data['deformation_distance'])
    }

# File uploader
uploaded_files = st.file_uploader(
    "Choose image files", 
    type=['png', 'jpg', 'jpeg', 'gif', 'bmp'],
    accept_multiple_files=True
)

# Save uploaded files and initialize their data
for i, uploaded_file in enumerate(uploaded_files):
    # Check if file exists in our data
    file_exists = any(data['filename'] == uploaded_file.name for data in st.session_state.files_data.values())
    if not file_exists:
        file_id = str(uuid.uuid4())
        save_annotation(file_id, uploaded_file.name, i)

# Display files table with status
if st.session_state.files_data:
    # Sort files by order
    sorted_files = sorted(st.session_state.files_data.values(), key=lambda x: x['order'])
    
    files_df = pd.DataFrame([
        {
            'Order': data['order'] + 1,  # 1-based index for display
            'File': data['filename'],
            'Status': data['status'][1],
            'Fiducial Points': sum(1 for p in data['points'] if p['label'] == 'Fiducial'),
            'Scale Points': sum(1 for p in data['points'] if p['label'] == 'Scale'),
            'Deformation Distance (mm)': data['deformation_distance'] if data['deformation_distance'] is not None else "Not Set"
        }
        for data in sorted_files
    ])
    
    # Color coding for status
    def color_status(val):
        if val == 'Complete':
            return 'color: green'
        elif val == 'Incomplete':
            return 'color: orange'
        elif val == 'Missing Distance':
            return 'color: purple'
        return 'color: red'
    
    st.markdown("### üìä Files Status")
    st.dataframe(
        files_df.style.applymap(color_status, subset=['Status']),
        hide_index=True
    )
    
    # File selection and annotation section
    st.markdown("### üéØ Image Annotation")
    selected_filename = st.selectbox(
        "Select image to annotate",
        options=[data['filename'] for data in sorted_files]
    )
    
    if selected_filename:
        # Find the file data by filename
        file_data = next(data for data in st.session_state.files_data.values() if data['filename'] == selected_filename)
        
        # Save the image temporarily
        temp_path = "temp_image.jpg"
        for uploaded_file in uploaded_files:
            if uploaded_file.name == selected_filename:
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getvalue())
                break
        
        # Get image dimensions
        with Image.open(temp_path) as img:
            width, height = img.size
            # Calculate dimensions maintaining aspect ratio with minimum size of 512
            scale = max(512 / width, 512 / height)
            display_width = int(width * scale)
            display_height = int(height * scale)
        
        # Point detection annotation
        points = pointdet(
            temp_path,
            label_list=label_list,
            points=[[p['point'][0], p['point'][1]] for p in file_data['points']],
            labels=[0 if p['label'] == 'Fiducial' else 1 for p in file_data['points']],
            height=display_height,
            width=display_width,
            point_width=3,
            use_space=True
        )
        
        # Display current annotation table
        if file_data['points']:
            df_data = []
            for i, point in enumerate(file_data['points']):
                df_data.append({
                    'Type': point['label'],
                    'Order': i + 1,
                    'X': f"{point['point'][0]:.1f}",
                    'Y': f"{point['point'][1]:.1f}"
                })
            
            df = pd.DataFrame(df_data)
            
            st.markdown("#### Point Coordinates")
            st.dataframe(
                df.style.applymap(
                    lambda x: 'color: red' if x == 'Fiducial' else 'color: green',
                    subset=['Type']
                ),
                hide_index=True
            )
        
        # Add deformation distance input after annotation display
        st.markdown("#### Deformation Distance")
        deformation_distance = st.number_input(
            "Enter deformation distance (mm)",
            min_value=0.0,
            value=float(file_data['deformation_distance']) if file_data['deformation_distance'] is not None else 0.0,
            step=0.1,
            help="Press Enter or click outside to save the value"
        )
        
        save_annotation(file_data['id'], file_data['filename'], file_data['order'], points, deformation_distance)

    # Debug section
    # st.markdown("### Debug Information")
    # st.markdown("All files data:")
    # st.json(st.session_state.files_data)

    # Analysis Section
    st.markdown("---")  # Horizontal rule
    st.markdown("## üî¨ Strain Analysis")
    
    # Check if all files are complete
    all_complete = all(data['status'][0] for data in st.session_state.files_data.values())
    
    if not all_complete:
        st.warning("""
        ‚ö†Ô∏è **Analysis Disabled**
        
        Complete these steps:
        1. Mark all points (5 fiducial + 2 scale)
        2. Set deformation distance
        3. Verify "Complete" status
        """)
    else:
        st.success("""
        ‚úÖ **Ready for Analysis**
        
        Next steps:
        1. Set scale length
        2. View results
        3. Export data
        """)
        
        # Scale length input
        st.markdown("### üìè Scale Calibration")
        st.markdown("Enter physical length of scale markers (mm)")
        scale_length = st.number_input(
            "Scale Length (mm)",
            min_value=0.0,
            value=st.session_state.last_scale_length,
            step=0.1
        )
        
        # Store scale length
        st.session_state.last_scale_length = scale_length
        
        # Run analysis if scale length changed or no analysis exists
        if (st.session_state.analysis_results is None or 
            st.session_state.analysis_results['scale_length'] != scale_length):
            
            # Process all files and calculate strain tensors
            strain_data = []
            for data in sorted_files:
                # Extract points
                fiducial_points = []
                scale_points = []
                for point in data['points']:
                    if point['label'] == 'Fiducial':
                        fiducial_points.append(point['point'])
                    else:
                        scale_points.append(point['point'])
                
                # Convert to numpy arrays
                fiducial_points = np.array(fiducial_points)
                scale_points = np.array(scale_points)
                
                # Normalize points
                normalized_points = normalize_points_by_scale(fiducial_points, scale_points, scale_length)
                
                # Calculate strain tensor
                strain_tensor = calculate_strain_tensor(normalized_points, normalized_points)  # Using same points for now
                
                strain_data.append({
                    'filename': data['filename'],
                    'deformation_distance': data['deformation_distance'],
                    'strain_tensor': strain_tensor
                })
            
            # Calculate regression results
            x_values = [d['deformation_distance'] for d in strain_data]
            regression_results = {}
            
            # X-axis strain
            y_values = [d['strain_tensor'][0,0] for d in strain_data]
            slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)
            regression_results['x_axis'] = {
                'slope': float(slope),
                'intercept': float(intercept),
                'r_squared': float(r_value**2),
                'p_value': float(p_value)
            }
            
            # Y-axis strain
            y_values = [d['strain_tensor'][1,1] for d in strain_data]
            slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)
            regression_results['y_axis'] = {
                'slope': float(slope),
                'intercept': float(intercept),
                'r_squared': float(r_value**2),
                'p_value': float(p_value)
            }
            
            # Shear strain
            y_values = [d['strain_tensor'][0,1] for d in strain_data]
            slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)
            regression_results['shear'] = {
                'slope': float(slope),
                'intercept': float(intercept),
                'r_squared': float(r_value**2),
                'p_value': float(p_value)
            }
            
            # Store results in session state
            st.session_state.analysis_results = {
                'strain_data': strain_data,
                'scale_length': scale_length,
                'regression_results': regression_results
            }
        
        # Display analysis results
        strain_data = st.session_state.analysis_results['strain_data']
        regression_results = st.session_state.analysis_results['regression_results']
        x_values = [d['deformation_distance'] for d in strain_data]
        
        # Create three columns for visualization
        col1, col2, col3 = st.columns(3)
        
        def format_scientific(value: float, unit: str = "") -> str:
            """Format number in scientific notation if too small or large."""
            if abs(value) < 1e-6 or (abs(value) > 1e6 and value != 0):
                return f"{value:.2e} {unit}"
            return f"{value:.6f} {unit}".rstrip('0').rstrip('.')
        
        with col1:
            st.markdown("### üìà X-Axis Strain (Œµxx)")
            y_values = [d['strain_tensor'][0,0] for d in strain_data]
            results = regression_results['x_axis']
            
            # Create plot
            fig, ax = plt.subplots()
            ax.scatter(x_values, y_values, color='blue', label='Data points')
            ax.plot(x_values, [results['slope']*x + results['intercept'] for x in x_values], 
                   color='red', label='Regression line')
            ax.set_xlabel('Deformation Distance (mm)')
            ax.set_ylabel('Strain (Œµxx)')
            ax.legend()
            st.pyplot(fig)
            
            # Display regression info with scientific formatting
            st.markdown(f"""
            **Regression Equation:**  
            Œµxx = {format_scientific(results['slope'], "mm‚Åª¬π")}x + {format_scientific(results['intercept'], "")}
            
            **R¬≤ Value:** {format_scientific(results['r_squared'], "")}
            **P-value:** {format_scientific(results['p_value'], "")}
            """)
            
            # Display data table with scientific formatting
            df_x = pd.DataFrame({
                'Distance (mm)': [f"{x:.2f}" for x in x_values],
                'Œµxx': [format_scientific(y, "") for y in y_values]
            })
            st.dataframe(df_x)
        
        with col2:
            st.markdown("### üìà Y-Axis Strain (Œµyy)")
            y_values = [d['strain_tensor'][1,1] for d in strain_data]
            results = regression_results['y_axis']
            
            # Create plot
            fig, ax = plt.subplots()
            ax.scatter(x_values, y_values, color='blue', label='Data points')
            ax.plot(x_values, [results['slope']*x + results['intercept'] for x in x_values], 
                   color='red', label='Regression line')
            ax.set_xlabel('Deformation Distance (mm)')
            ax.set_ylabel('Strain (Œµyy)')
            ax.legend()
            st.pyplot(fig)
            
            # Display regression info with scientific formatting
            st.markdown(f"""
            **Regression Equation:**  
            Œµyy = {format_scientific(results['slope'], "mm‚Åª¬π")}x + {format_scientific(results['intercept'], "")}
            
            **R¬≤ Value:** {format_scientific(results['r_squared'], "")}
            **P-value:** {format_scientific(results['p_value'], "")}
            """)
            
            # Display data table with scientific formatting
            df_y = pd.DataFrame({
                'Distance (mm)': [f"{x:.2f}" for x in x_values],
                'Œµyy': [format_scientific(y, "") for y in y_values]
            })
            st.dataframe(df_y)
        
        with col3:
            st.markdown("### üìà Shear Strain (Œµxy)")
            y_values = [d['strain_tensor'][0,1] for d in strain_data]
            results = regression_results['shear']
            
            # Create plot
            fig, ax = plt.subplots()
            ax.scatter(x_values, y_values, color='blue', label='Data points')
            ax.plot(x_values, [results['slope']*x + results['intercept'] for x in x_values], 
                   color='red', label='Regression line')
            ax.set_xlabel('Deformation Distance (mm)')
            ax.set_ylabel('Strain (Œµxy)')
            ax.legend()
            st.pyplot(fig)
            
            # Display regression info with scientific formatting
            st.markdown(f"""
            **Regression Equation:**  
            Œµxy = {format_scientific(results['slope'], "mm‚Åª¬π")}x + {format_scientific(results['intercept'], "")}
            
            **R¬≤ Value:** {format_scientific(results['r_squared'], "")}
            **P-value:** {format_scientific(results['p_value'], "")}
            """)
            
            # Display data table with scientific formatting
            df_xy = pd.DataFrame({
                'Distance (mm)': [f"{x:.2f}" for x in x_values],
                'Œµxy': [format_scientific(y, "") for y in y_values]
            })
            st.dataframe(df_xy)
        
        # Data export section
        st.markdown("---")  # Horizontal rule
        st.markdown("### üì• Data Export")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìÑ Raw Data")
            st.markdown("""
            Available formats:
            - JSON: File data + scale length
            - CSV: Strain components
            """)
            
            # Convert strain data to JSON-serializable format
            raw_data = {
                'files_data': st.session_state.files_data,
                'scale_length': scale_length
            }
            json_str = json.dumps(raw_data, indent=2)
            st.download_button(
                "Download Raw Data (JSON)",
                json_str,
                file_name="raw_data.json",
                mime="application/json"
            )
            
            # Convert to CSV
            csv_data = []
            for data in strain_data:
                csv_data.append({
                    'filename': data['filename'],
                    'deformation_distance': data['deformation_distance'],
                    'strain_xx': data['strain_tensor'][0,0],
                    'strain_yy': data['strain_tensor'][1,1],
                    'strain_xy': data['strain_tensor'][0,1]
                })
            df_csv = pd.DataFrame(csv_data)
            csv_str = df_csv.to_csv(index=False)
            st.download_button(
                "Download Raw Data (CSV)",
                csv_str,
                file_name="raw_data.csv",
                mime="text/csv"
            )
        
        with col2:
            st.markdown("#### üìä Analysis Results")
            st.markdown("""
            Available formats:
            - JSON: Regression parameters
            - CSV: Regression data
            """)
            
            # Download JSON
            json_str = json.dumps(regression_results, indent=2)
            st.download_button(
                "Download Analysis Results (JSON)",
                json_str,
                file_name="analysis_results.json",
                mime="application/json"
            )
            
            # Download CSV
            analysis_df = pd.DataFrame([
                {'component': 'x_axis', **regression_results['x_axis']},
                {'component': 'y_axis', **regression_results['y_axis']},
                {'component': 'shear', **regression_results['shear']}
            ])
            csv_str = analysis_df.to_csv(index=False)
            st.download_button(
                "Download Analysis Results (CSV)",
                csv_str,
                file_name="analysis_results.csv",
                mime="text/csv"
            )
        
        # Important notice
        st.warning("""
        ‚ö†Ô∏è **New Analysis**
        
        To start fresh:
        1. Refresh page
        2. Upload images
        3. Mark points
        4. Set scale length
        """)

# Clean up temporary file
if os.path.exists("temp_image.jpg"):
    os.remove("temp_image.jpg")
